{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTree_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedantdave77/Machine_Learning_feature_selection/blob/master/DecisionTree_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtNcnzRstuiX",
        "colab_type": "text"
      },
      "source": [
        "## Objective:\n",
        "### Measure the Performance of Decision Tree algorithm with 10 fold cross validation with KNN, we use seperation of 25 dataset with 5 set spliting and average value of (out of sample) error taken in to consideration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6Lqvz5ro_MS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import tree\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "#Read data in X and Y\n",
        "df=pd.read_excel('Gear1.xlsx')\n",
        "df_shuffle=shuffle(df);\n",
        "df=df_shuffle;\n",
        "y = df['Class']\n",
        "x1 = df.drop(['Class'],axis=1)\n",
        "\n",
        "#Data preprocessing\n",
        "x=x1.loc[:,(df!=0).any(axis=0)];\n",
        "scaler=MinMaxScaler(copy=True,feature_range=(0,1));\n",
        "x_scaled=scaler.fit_transform(x)\n",
        "x=x_scaled\n",
        "\n",
        "# use train and test split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
        "\n",
        "# check classification accuracy of classification tree\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "dt = dt.fit(x_train, y_train)\n",
        "y_pred = dt.predict(x_test)\n",
        "print(metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# simulate splitting a dataset of 25 observations into 5 folds\n",
        "kf = KFold(n_splits=5, shuffle=False).split(range(25))\n",
        "\n",
        "# print the contents of each training and testing set\n",
        "print('{} {:^61} {}'.format('Iteration', 'Training set observations', 'Testing set observations'))\n",
        "for iteration, data in enumerate(kf, start=1):\n",
        "    print('{:^9} {} {:^25}'.format(iteration, data[0], str(data[1])))\n",
        "   \n",
        "  \n",
        "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "scores = cross_val_score(knn, x, y, cv=10, scoring='accuracy')\n",
        "print(scores)\n",
        "\n",
        "# use average accuracy as an estimate of out-of-sample accuracy\n",
        "print(scores.mean())\n",
        "\n",
        "# search for an optimal value of K for KNN\n",
        "#inner CV loop\n",
        "k_range = list(range(1, 11))\n",
        "k_scores = []\n",
        "for k in k_range:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, x_train, y_train, cv=10, scoring='accuracy')\n",
        "    k_scores.append(scores.mean())\n",
        "print(k_scores)\n",
        "%matplotlib inline\n",
        "\n",
        "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
        "plt.plot(k_range, k_scores)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Cross-Validated Accuracy')\n",
        "\n",
        "# 10-fold cross-validation for decision tree\n",
        "f_measure = cross_val_score(dt,x,y,cv=10,scoring='f1_weighted')\n",
        "accuracy = cross_val_score(dt, x, y, cv=10, scoring='accuracy')\n",
        "\n",
        "#Create Table\n",
        "columns=np.transpose([f_measure,accuracy])\n",
        "df=pd.DataFrame(columns,columns=['f_measure','accuracy'])\n",
        "col_1=np.transpose(f_measure)\n",
        "col_2=np.transpose(accuracy)\n",
        "print('f_measure',col_1)\n",
        "print('accuracy',col_2)\n",
        "\n",
        "#export file\n",
        "file='Res-DT'+'.xlsx'\n",
        "exportfile=df.to_excel(file,index= None,header=True)\n",
        "files.download(file)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}